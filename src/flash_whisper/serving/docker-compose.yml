services:
  server:
    build:
      context: .
      dockerfile: Dockerfile.server
    image: speed/whisper-server:24.09
    container_name: whisper-server
    restart: unless-stopped
    networks:
      - whisper-network
    environment:
      - PYTHONIOENCODING=utf-8
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: 1g
    command: >
      /bin/bash -c "cd ./converter && bash ./build.sh && cd /workspace && bash prepare.sh"

  client:
    build:
      context: .
      dockerfile: Dockerfile.client.go
    image: speed/whisper-client:1.0
    container_name: whisper-client
    pid: host
    restart: unless-stopped
    networks:
      - whisper-network
    environment:
      - TRITON_SERVER_ENDPOINT=whisper-server:8001
    ports:
      - "8080:9090"
    command: ["--port", "9090", "--workers", "8"]

networks:
  whisper-network:
    driver: bridge

#   client:
#     build:
#       context: .
#       dockerfile: Dockerfile.client.python
#     image: speed/whisper-client:1.0
#     container_name: whisper-client
#     restart: unless-stopped
#     volumes:
#       - ./client/python:/workspace
#     networks:
#       - whisper-network
#     environment:
#       - TRITON_SERVER_ENDPOINT=whisper-server:8001
#     ports:
#       - "8080:9090"
#     command: ["--port", "9090", "--workers", "8"]

# networks:
#   whisper-network:
#     driver: bridge